{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6-F0OzF2Its"
   },
   "source": [
    "# Week 8 Machine Learning Homework\n",
    "\n",
    "## Instructions\n",
    "Complete all exercises below by writing code in the cells provided. Focus on implementing and understanding the sigmoid function and evaluation metrics.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fkO3LjH2Nl9"
   },
   "source": [
    "### Exercise 1: Sigmoid Function Implementation\n",
    "\n",
    "Implement the sigmoid function from scratch and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PZsvY6k2Wkq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exercise 1: Sigmoid Function Implementation\n",
    "def sigmoid(x):\n",
    "    \"\"\"Compute the sigmoid function for input x (scalar or array).\"\"\"\n",
    "    x_arr = np.asarray(x, dtype=float)\n",
    "\n",
    "    # Numerically stable sigmoid\n",
    "    out = np.empty_like(x_arr, dtype=float)\n",
    "    pos = x_arr >= 0\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-x_arr[pos]))\n",
    "    exp_x = np.exp(x_arr[~pos])\n",
    "    out[~pos] = exp_x / (1.0 + exp_x)\n",
    "\n",
    "    # Return a scalar if a scalar was provided\n",
    "    if np.isscalar(x):\n",
    "        return float(out)\n",
    "    return out\n",
    "\n",
    "# Create a plot of the sigmoid function\n",
    "x = np.linspace(-10, 10, 400)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, linewidth=2)\n",
    "plt.title('Sigmoid Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('sigmoid(x)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()\n",
    "\n",
    "# Test your implementation with specific values\n",
    "test_values = [-5, -2, 0, 2, 5]\n",
    "print(\"Sigmoid function test:\")\n",
    "for val in test_values:\n",
    "    print(f\"sigmoid({val:>2}) = {sigmoid(val):.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVBUnJL92h9D"
   },
   "source": [
    "### Exercise 2: Logistic Regression Probability Calculation\n",
    "\n",
    "Use the sigmoid function to calculate class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEF9_Lok2mj2"
   },
   "outputs": [],
   "source": [
    "# Sample feature values and model coefficients\n",
    "feature1 = 1.5\n",
    "feature2 = -0.8\n",
    "bias = 0.5\n",
    "coef1 = 0.8\n",
    "coef2 = -0.3\n",
    "\n",
    "# Exercise 2: Logistic Regression Probability Calculation\n",
    "# Calculate the linear combination z = w1*x1 + w2*x2 + b\n",
    "z = coef1 * feature1 + coef2 * feature2 + bias\n",
    "\n",
    "# Use sigmoid to calculate probability of class 1\n",
    "probability = sigmoid(z)\n",
    "\n",
    "print(f\"Linear combination z: {z:.4f}\")\n",
    "print(f\"Probability of class 1: {probability:.4f}\")\n",
    "\n",
    "# Implement a function that takes features, coefficients, and bias,\n",
    "# and returns both probability and prediction\n",
    "def predict_probability(features, coefficients, bias, threshold=0.5):\n",
    "    \"\"\"Return (probability, prediction) using a sigmoid model.\"\"\"\n",
    "    features = np.asarray(features, dtype=float)\n",
    "    coefficients = np.asarray(coefficients, dtype=float)\n",
    "\n",
    "    z = float(np.dot(features, coefficients) + bias)\n",
    "    prob = float(sigmoid(z))\n",
    "    pred = 1 if prob >= threshold else 0\n",
    "    return prob, pred\n",
    "\n",
    "# Test the function\n",
    "test_features = [1.5, -0.8]\n",
    "test_coefficients = [0.8, -0.3]\n",
    "test_bias = 0.5\n",
    "\n",
    "prob, pred = predict_probability(test_features, test_coefficients, test_bias)\n",
    "print(f\"\\nTest - Probability: {prob:.4f}, Prediction: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owEoPTz23AoJ"
   },
   "source": [
    "### Exercise 3: Confusion Matrix Implementation\n",
    "\n",
    "Implement a confusion matrix calculation from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EKQmDmC3IPE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample true labels and predictions\n",
    "y_true = [0, 1, 0, 1, 1, 0, 1, 0, 0, 1]\n",
    "y_pred = [0, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n",
    "\n",
    "# Exercise 3: Confusion Matrix Implementation\n",
    "def calculate_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Calculate confusion matrix components: TP, TN, FP, FN.\"\"\"\n",
    "    TP = TN = FP = FN = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            TP += 1\n",
    "        elif yt == 0 and yp == 0:\n",
    "            TN += 1\n",
    "        elif yt == 0 and yp == 1:\n",
    "            FP += 1\n",
    "        elif yt == 1 and yp == 0:\n",
    "            FN += 1\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected labels: y_true={yt}, y_pred={yp}\")\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "# Test the function\n",
    "TP, TN, FP, FN = calculate_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix Components:\")\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "\n",
    "# Create a visualization of the confusion matrix\n",
    "conf_matrix = np.array([[TN, FP],\n",
    "                        [FN, TP]])\n",
    "\n",
    "plt.figure(figsize=(5.5, 4.5))\n",
    "plt.imshow(conf_matrix, interpolation='nearest')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks([0, 1], ['Pred 0', 'Pred 1'])\n",
    "plt.yticks([0, 1], ['True 0', 'True 1'])\n",
    "\n",
    "# Annotate counts\n",
    "for (i, j), v in np.ndenumerate(conf_matrix):\n",
    "    plt.text(j, i, str(v), ha='center', va='center', fontsize=12)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGFu3IuX3V-w"
   },
   "source": [
    "### Exercise 4: Classification Metrics Calculation\n",
    "\n",
    "Implement accuracy, precision, recall, and F1-score from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGKdn5im3a0J"
   },
   "outputs": [],
   "source": [
    "# Exercise 4: Classification Metrics Calculation\n",
    "def calculate_metrics(TP, TN, FP, FN):\n",
    "    \"\"\"Calculate accuracy, precision, recall, and F1-score.\"\"\"\n",
    "    total = TP + TN + FP + FN\n",
    "\n",
    "    accuracy = (TP + TN) / total if total else 0.0\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0.0\n",
    "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Calculate metrics using the confusion matrix from Exercise 3\n",
    "accuracy, precision, recall, f1 = calculate_metrics(TP, TN, FP, FN)\n",
    "\n",
    "print(\"\\nClassification Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
